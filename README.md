# Домашнее задание к уроку 5: Аугментации и работа с изображениями

## Задание 1: Стандартные аугментации torchvision 
- Создайте пайплайн стандартных аугментаций torchvision (например, RandomHorizontalFlip, RandomCrop, ColorJitter, RandomRotation, RandomGrayscale).
- Примените аугментации к 5 изображениям из разных классов (папка train).
- Визуализируйте:
  - Оригинал
  - Результат применения каждой аугментации отдельно
  - Результат применения всех аугментаций вместе

### Описание: 

1. Создание пайплайна аугментаций:

- Определены различные методы аугментации изображений (RandomHorizontalFlip, RandomCrop, ColorJitter и др.), включая комбинированный вариант (AllTogether).

Каждая аугментация имеет свои параметры (например, вероятность, степень изменения цвета и т. д.).

2. Загрузка датасета:

- Используется пользовательский датасет CustomImageDataset, загружающий изображения из папки data/train.

3. Выбор примеров изображений:

- Для визуализации отбирается по одному изображению из каждого класса (всего 5 классов).

4. Визуализация аугментаций:

- Для каждого выбранного изображения применяются все аугментации из пайплайна.
- Результаты отображаются в виде сетки с оригинальным изображением и его аугментированными версиями.

### Примеры:

![image](https://github.com/user-attachments/assets/bab6d0a7-e77c-4e87-8909-d6061fdf701b)

![image](https://github.com/user-attachments/assets/48b515d3-b340-454a-887e-4cf8319c569e)

### Вывод: 

Код демонстрирует применение различных аугментаций к изображениям из датасета для увеличения разнообразия данных. Это полезно для:

- Улучшения обобщающей способности моделей машинного обучения.
- Искусственного расширения обучающей выборки.
- Тестирования устойчивости модели к изменениям входных данных.

Комбинированная аугментация (AllTogether) позволяет создать более разнообразные варианты изображений, что особенно полезно при ограниченном объеме исходных данных. Визуализация помогает оценить эффект от каждой аугментации и подобрать оптимальные параметры.

## Задание 2: Кастомные аугментации 
- Реализуйте минимум 3 кастомные аугментации (например, случайное размытие, случайная перспектива, случайная яркость/контрастность).
- Примените их к изображениям из train.
- Сравните визуально с готовыми аугментациями из extra_augs.py.

### Описание:

1. Загрузка данных:

- Определены пути к данным и список персонажей (characters).
- Функция get_valid_images() кэширует список валидных изображений (.jpg, .jpeg, .png, .bmp) из указанных папок.
- load_random_image() загружает случайное изображение, используя сначала PIL, а затем OpenCV (если PIL не сработал).

2. Кастомные аугментации:

- random_blur(): применяет размытие (гауссово или медианное) с случайным размером ядра.
- random_perspective(): искажает изображение с помощью перспективного преобразования.
- random_brightness_contrast(): изменяет яркость и контрастность.
- apply_custom_augmentations(): применяет указанные аугментации с вероятностью 50%.

3. Дополнительные аугментации (PyTorch):

- apply_extra_augs(): использует аугментации из val.extra_augs (например, RandomErasing, CutOut, Solarize и др.), преобразуя изображение в тензор и обратно.

4. Визуализация:

- compare_augmentations() загружает случайное изображение, применяет кастомные и дополнительные аугментации, а затем отображает оригинал и аугментированные версии.

5. Проверка данных:

- Проверяется доступность папок и файлов перед запуском аугментаций.

### Примеры: 

![image](https://github.com/user-attachments/assets/7cdb68fb-2d85-4f8b-b510-83e88afffef9)

![image](https://github.com/user-attachments/assets/3d967969-fe1c-4253-8458-3657393714fe)

### Вывод: 

Код демонстрирует два подхода к аугментации изображений:

1. Классический (OpenCV):

- Простые, но эффективные методы (размытие, перспектива, яркость/контраст).
- Работает напрямую с numpy-массивами.

2. PyTorch-based:

- Более сложные аугментации (например, RandomErasing, Solarize).
- Требует преобразования в тензор и нормализацию.

## Задание 3: Анализ датасета 
- Подсчитайте количество изображений в каждом классе.
- Найдите минимальный, максимальный и средний размеры изображений.
- Визуализируйте распределение размеров и гистограмму по классам.

### Описание:

1. Загрузка данных:

- Создается объект датасета CustomImageDataset без аугментаций для анализа.
- Для каждого изображения собирается информация: класс, ширина, высота и соотношение сторон.

2. Сбор статистики:

- Данные сохраняются в список словарей и конвертируются в DataFrame для удобного анализа.

3. Анализ данных:

- Количество изображений по классам: вывод распределения количества изображений для каждого класса.
- Размеры изображений: вычисление минимальных, максимальных и средних значений ширины и высоты.
- Соотношение сторон: анализ распределения соотношения ширины к высоте.

4. Визуализация:

- Гистограмма по классам: показывает количество изображений в каждом классе.
- Scatter plot размеров: визуализирует соотношение ширины и высоты всех изображений.
- Гистограмма соотношения сторон: отображает распределение коэффициента width/height.

### Пример: 

![image](https://github.com/user-attachments/assets/8687286b-68f9-46ed-b273-ac4f97c529e2)

### Вывод: 

Код выполняет анализ изображений в датасете, предоставляя важную статистику и визуализацию. Это помогает понять:

1. Баланс классов:

- Есть ли дисбаланс в количестве изображений между классами (может потребоваться балансировка).

2. Размеры изображений:

- Разброс размеров (минимальный, максимальный, средний) помогает определить параметры аугментаций и предобработки (например, resize или crop).

3. Соотношение сторон:

- Показывает, насколько разнообразны формы изображений (может влиять на выбор стратегии аугментации, например, padding или random crop).

## Задание 4: Pipeline аугментаций
- Реализуйте класс AugmentationPipeline с методами:
  - add_augmentation(name, aug)
  - remove_augmentation(name)
  - apply(image)
  - get_augmentations()
- Создайте несколько конфигураций (light, medium, heavy).
- Примените каждую конфигурацию к train и сохраните результаты.

### Пример: 

![image](https://github.com/user-attachments/assets/5c1fb89c-53dd-4747-99d7-84068823e70e)

## Задание 5: Эксперимент с размерами 
- Проведите эксперимент с разными размерами изображений (например, 64x64, 128x128, 224x224, 512x512).
- Для каждого размера измерьте время загрузки и применения аугментаций к 100 изображениям, а также потребление памяти.
- Постройте графики зависимости времени и памяти от размера.

### Описание задания 4-5:

1. Создание пайплайна аугментаций:

- Реализован класс AugmentationPipeline для управления последовательностью преобразований
- Поддерживает добавление/удаление аугментаций по имени
- Последовательно применяет все преобразования к изображению

2. Реализация базовых аугментаций:

- Поворот (random_rotate): случайный угол ±15°
- Отражение (random_flip): горизонтальный флип с вероятностью 50%
- Цветовые искажения (color_jitter): случайное изменение яркости
- Размытие (gaussian_blur): гауссово размытие 5×5
- Комплексное искажение (heavy_distortion): комбинация поворота, цветокоррекции и изменения контраста

3. Предустановленные конфигурации:

- Легкие аугментации (флип + цвет)
- Средние (поворот + флип + размытие)
- Сильные (комплексные искажения + дополнительные преобразования)

4. Демонстрация работы:

- Загрузка тестового изображения
- Применение всех трех пайплайнов
- Визуальное сравнение результатов
- Сохранение аугментированных изображений

### Пример: 

![image](https://github.com/user-attachments/assets/a195bea9-20ab-475f-b979-ddc4112264e8)

![image](https://github.com/user-attachments/assets/b91c673c-11a8-43d0-85f4-48dbb8a3a1d2)

### Вывод по работам 4-5: 

Представленный код реализует гибкую систему аугментации изображений с ключевыми преимуществами:

1. Модульность архитектуры:

- Каждая аугментация - независимая функция
- Легко расширяется новыми преобразованиями

2. Гибкость использования:

- Возможность создавать кастомные комбинации аугментаций
- Три готовых уровня интенсивности (light/medium/heavy)

3. Практическая ценность:

- Визуализация результатов для контроля качества
- Автоматическое сохранение преобразованных изображений

## Задание 6: Дообучение предобученных моделей 
- Возьмите одну из предобученных моделей torchvision (например, resnet18, efficientnet_b0, mobilenet_v3_small).
- Замените последний слой на количество классов вашего датасета.
- Дообучите модель на train, проверьте качество на val.
- Визуализируйте процесс обучения (loss/accuracy).

### Описание: 

1. Подготовка данных:

- Создание пайплайна преобразований изображений (изменение размера, нормализация)
- агрузка тренировочного и валидационного датасетов
- Проверка наличия данных и создание DataLoader

2. Настройка модели:

- Использование предобученной ResNet18
- Заморозка всех слоев кроме последнего
- Замена последнего слоя под нужное количество классов

4. Процесс обучения:

- Использование оптимизатора Adam и функции потерь CrossEntropy
- Цикл обучения с расчетом метрик (потери, точность)
- Валидация после каждой эпохи (при наличии данных)

5. Визуализация и сохранение:

- Построение графиков потерь и точности
- Сохранение модели и графиков обучения

### Пример:

![image](https://github.com/user-attachments/assets/7f0b4b86-a231-4451-ac4f-1fafce759bd9)

### Вывод: 

Код представляет собой полный пайплайн трансферного обучения на базе ResNet18 с ключевыми особенностями:

1. Гибкость:

- Поддержка как GPU, так и CPU
- Автоматическая обработка случаев отсутствия валидационных данных

2. Надежность:

- Проверки наличия данных перед обучением
- Постепенное логирование процесса обучения

3. Практическая ценность:

- Визуализация метрик обучения
- Сохранение обученной модели

## Общий вывод:

Три ключевых аспекта работы с изображениями в машинном обучении: аугментация данных, анализ датасета и обучение модели.

1. Аугментация данных

- Реализован гибкий и модульный пайплайн для применения различных преобразований к изображениям (повороты, отражения, изменение цветов, размытие и др.).
- Поддерживается три уровня аугментаций (легкие, средние, сильные), что позволяет адаптировать их под разные задачи.
- Вывод: Такой подход полезен для увеличения разнообразия данных, особенно при работе с небольшими датасетами.

2. Анализ датасета

- Проведена статистическая оценка изображений (размеры, соотношение сторон, распределение по классам).
- Визуализация (гистограммы, scatter plot) помогает выявить дисбаланс классов и разнородность размеров.
- Вывод: Анализ критически важен для выбора стратегии предобработки (например, обрезка, паддинг) и балансировки данных.

3. Обучение модели

- Использована предобученная ResNet18 с замороженными слоями и заменой классификатора.
- Реализован полный цикл обучения с валидацией, расчетом метрик и сохранением модели.
- Вывод: Трансферное обучение эффективно для задач классификации, особенно при ограниченном объеме данных.

Представленные решения образуют полный pipeline для работы с изображениями: от анализа данных до обучения модели. Их можно использовать как основу для более сложных задач, таких как детекция объектов или сегментация. Ключевые преимущества – гибкость, модульность и практическая применимость.
